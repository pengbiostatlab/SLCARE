---
title: "Estimation procedure"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Estimation_procedure}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


Let $Z_{i} = (1, \tilde{Z_{i} ^{T}})^{T}$ and $\beta _{0,k} = (log(\eta _{0,k}) , \tilde{\beta_{0,k} ^{T}})^{T}$, by (1), (2) and $E(W_{i} | \tilde {Z} _{i} , \xi _{i} = k) = 1$ we can get
$$
E[N_{i} ^{*} (t) | \xi_{i} = k, Z_{i}  \} = \mu_{0} (t) exp(Z_{i} ^{T} \beta _{0,k}) \tag{1}
$$
Where: $\mu _{0} (t) = \int _{0} ^{t} \lambda _{0} (s) ds$

Given $C_{i}$ and $(N_{i} ^{*} , \xi _{i})$ are independent given $Z_{i}$, so we have $E[\frac{N_{i} ^{*} (C _{i})}{\mu_{0} (C_{i})} | \xi _{i} = k, Z_{i}] = exp(Z^{T} _{i} \beta _{0,k})$

Thus:
$$
E[ I(\xi _{i} = k) Z_{i} \{ \frac{N_{i} ^{*} (C _{i})}{\mu_{0} (C_{i})}  - exp(Z_{i} ^{T} \beta _{0,k}) \}] = 0 \tag{2}
$$

To build estimating equation for $\beta _{0,k}$, we need to deal with unobserved  $\xi_{i}$

The authors recover the missing information on $I(\xi _{i} =k)$ by conditioning it on the observed $Z_{i}, C_{i}$ and $D_{i} = N_{i}(C_{i})$ 

Let $\tau_{i,k} = E[I(\xi _{i} = k) | Z_{i}, D_{i}, C_{i}]$, we have
$$
\tau _{i,k} = \frac{P(D_{i} = d_{i} | \xi _{i} = k, Z _{i}, C_{i}) P(\xi _{i} = k | Z_{i}, C_{i})}{\sum _{l = 1} ^{K} P(D_{i} = d_{i} | \xi _{i} = l, Z _{i}, C_{i}) P(\xi _{i} = l | Z_{i}, C_{i})} \tag{3}
$$

- $\xi_{i}$ can be modeled by multinomial logistic regression, so we have:

$$
P(\xi _{i} = k | Z_{i}, C_{i}) = p_{k}(\alpha _{0} , \tilde{Z} _{i}) = \frac{exp(\tilde{Z} _{i} ^{T} \alpha _{0,k})}{\sum _{l = 1} ^{K} exp(\tilde{Z} _{i} ^{T} \alpha _{0,l})} \tag{4}
$$

- As shown in model assumption (SLCARE section), $N_{i} ^{*} (t)$ can be treated as a non-homogeneous Poisson process with mean $exp(Z^{T}\beta _{k})W\mu_{0}(t)$, thus $\{ \mu_{0}(T^{(i)}) \}$ can be viewed as random variables generated from a Poisson process with mean $exp(Z^{T}\beta _{k})Wt$.  Therefore, Let $T^{(0)} = 0$, $\{ \mu_{0}(T^{(j)}) - \mu_{0}(T^{(j-1)}) \}$  , $\{ \mu_{0}(T^{(d)}) \}$ follows exponential, gamma distribution.

  As $P ( D _{i} = d_{i} | \xi _{i} = k , Z _{i}, C _{i}) = P ( \mu _{0}(T^{(d)}), \mu_{0} (C) | \xi _{i} = k , Z _{i}, C _{i})$, we have:
  
$$
  P ( D _{i} = d_{i} | \xi _{i} = k , Z _{i}, C _{i}) = \int _{0} ^{\infty} \frac{ \{  exp(Z_{i} ^{T} \beta _{0,k}) w \cdot \mu_{0}(C _{i}) \} ^{d_{i}} }{d_{i} !} exp \{ - exp(Z_{i} ^{T} \beta _{0,k}) w \cdot \mu _{0} (C _{i}) \} \cdot f _{W} (w) dw    \tag{5}
$$

  

By (2) - (5)

we can have 1st estimating equation:
$$
S_{1,n,k}(\alpha, \beta, \mu_{0}) = \frac{1}{n}\sum _{i = 1} ^{n} \tau_{ik}(\alpha, \beta, \mu_{0}) Z_{i} \{  \frac{N_i ^{*} (C _{i})}{\mu_{0} (C_{i})} - exp(Z_{i} ^{T} \beta_{k}) \} = 0,~~~k = 1, \cdots , K  \tag{6}
$$


Based on logistic regression model, the score equation when $\xi _{i}$ are observed is:
$$
\sum _{ i = 1} ^{n} \sum _{k = 1} ^{K} I(\xi _{i} = k) \frac{\partial }{\partial \alpha} log ~p_{k}(\alpha, \tilde{Z_{i}}) = 0  \tag{7}
$$
Again by conditional score, we can have our 2nd estimating equation:
$$
S_{2,n,k}(\alpha, \beta, \mu_{0}) = \frac{1}{n}\sum _{i = 1} ^{n} \tau_{ik}(\alpha, \beta, \mu_{0}) ( \tilde{Z_{i}} - \frac{exp(\tilde{Z} _{i} ^{T} \alpha _{k}) \tilde{Z_{i}}}{\sum _{j = 1} ^{K} exp(\tilde{Z} _{i} ^{T} \alpha _{j})} ) = 0,~~~k = 1, \cdots , K  \tag{8}
$$
In (10) and (11), $\mu _{0}(t)$ can be evaluated by a Nelson-Aalen type estimator, under the assumed multiplicative intensity model. We can have $\hat{\mu} (t) = exp\{ \hat{H} (t)  \} $ with $\hat{H}(t) = - \int _{t} ^{\upsilon ^{*}} \frac{\sum _{i = 1} ^{n} d N_{i}(s)}{\sum _{i = 1} ^{n} I(C_{i} \geq s) N_{i}(s)}$.(9)

Finally, the authors proposed the estimating equations for $\alpha _{0}$ and $\beta _{0}$:
$$
n^{1/2} S_{1,n}(\alpha, \beta, \hat{\mu}) = 0 \tag{10}
$$

$$
n^{1/2} S_{2,n}(\alpha, \beta, \hat{\mu}) = 0 \tag{11}
$$

where $S_{j,n} (\alpha, \beta, \hat{\mu}) = ( S_{j,n,1} (\alpha, \beta, \hat{\mu})^{T}, \cdots , S_{j,n,K} (\alpha, \beta, \hat{\mu})^{T} )^{T}$, $j = 1,2$

